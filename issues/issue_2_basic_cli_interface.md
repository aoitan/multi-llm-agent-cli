# 基本的なCLIインターフェースの実装

## 概要
コマンドラインからの入力受付とLLM応答の表示、モデル選択機能を含む基本的なCLIインターフェースを実装する。

## 優先度
高

## 種別
タスク

## 詳細
* コマンドライン引数のパース:
    * `multi-llm-agent-cli chat <prompt> --model <model_name>` の形式でチャットコマンドを受け付ける。
    * `multi-llm-agent-cli model list` の形式でモデル一覧表示コマンドを受け付ける。
    * `--help` または `-h` でヘルプメッセージを表示する。
    * 不明なコマンドや引数に対してはエラーメッセージとヘルプを表示する。
    * `prompt` はスペースを含む場合があるため、適切にパースする（引用符で囲むなど）。
* ユーザー入力の受付:
    * チャットコマンド実行時、プロンプトが指定されない場合は、対話モードに移行し、ユーザーからの入力を継続的に受け付ける。
    * 対話モードでは、ユーザーが特定のコマンド（例: `/exit`, `/quit`）を入力するまでチャットを継続する。
* LLM応答の整形と表示:
    * Ollama APIからのストリーミング応答をリアルタイムで表示する。
    * LLMの応答は、読みやすいように整形して表示する（初期実装ではシンプルなテキスト表示）。
* モデル選択コマンドの実装:
    * `multi-llm-agent-cli model list` でOllamaに登録されているモデルの一覧を表示する。
    * `multi-llm-agent-cli chat` コマンドで `--model` オプションが指定されない場合、デフォルトモデルを使用する。

## 作業チェックリスト
* [ ] コマンドライン引数パースの仕組み構築
* [ ] ユーザー入力受付のプロトタイプ実装
* [ ] LLM応答表示のプロトタイプ実装
* [ ] モデル選択コマンドの実装

## 備考
なし