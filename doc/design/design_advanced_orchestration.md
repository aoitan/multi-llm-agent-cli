# 高度なオーケストレーションの設計

## 概要
指示者LLM（Orchestrator LLM）と作業者LLM（Worker LLM）を連携させ、複雑なタスクを協調して実行するオーケストレーションの仕組みを設計します。これにより、より高度な問題解決能力と柔軟性を提供します。

## 役割定義
- **指示者LLM (Orchestrator LLM)**:
    - ユーザーからの要求を理解し、タスクを分解します。
    - 分解されたタスクを作業者LLMに割り当てます。
    - 作業者LLMからの結果を統合し、最終的な応答を生成します。
    - 必要に応じて、作業者LLMに再指示を出します。
- **作業者LLM (Worker LLM)**:
    - 指示者LLMから割り当てられた特定のサブタスクを実行します。
    - 実行結果を指示者LLMに報告します。
    - 必要に応じて、外部ツール（未実装）を使用します。

## 連携プロトコル
指示者LLMと作業者LLM間のコミュニケーションには、MCPを拡張したプロトコルを使用することを検討します。具体的には、以下のメッセージタイプを定義します。

### 指示者LLM -> 作業者LLM
- `assign_task`: 作業者LLMにサブタスクを割り当てます。
    ```json
    {
      "type": "assign_task",
      "payload": {
        "task_id": "一意のタスクID",
        "description": "サブタスクの説明",
        "input": { /* サブタスクに必要な入力データ */ }
      }
    }
    ```

### 作業者LLM -> 指示者LLM
- `task_result`: サブタスクの実行結果を報告します。
    ```json
    {
      "type": "task_result",
      "payload": {
        "task_id": "関連するタスクID",
        "status": "completed" | "failed" | "needs_clarification",
        "output": { /* 実行結果データ */ },
        "message": "ステータスに関するメッセージ (例: エラーメッセージ、質問)"
      }
    }
    ```

## ワークフロー管理
MCPサーバーがオーケストレーションのハブとなり、指示者LLMと作業者LLM間のメッセージングを仲介します。サーバーは、タスクの状態を追跡し、必要に応じてLLMにメッセージをルーティングします。

## 実装の検討事項
- **LLMの選択**: 指示者LLMと作業者LLMには、異なる特性を持つモデル（例: 指示者には推論能力の高いモデル、作業者には特定のタスクに特化したモデル）を割り当てられるようにします。
- **コンテキストの共有**: 指示者LLMと作業者LLM間で、関連するコンテキスト（会話履歴、中間結果など）を効率的に共有する仕組みを検討します。
- **エラーハンドリングとリカバリ**: 作業者LLMが失敗した場合の指示者LLMによるリカバリ戦略を設計します。
- **ループ検出と終了条件**: 無限ループを防ぐためのメカニズムと、タスクの終了条件を定義します。

## 今後のステップ
- 指示者LLMと作業者LLMのプロトタイプ実装。
- ワークフロー管理ロジックの実装。
- ツール利用との連携。
