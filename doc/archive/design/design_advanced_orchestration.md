# 高度なオーケストレーションの設計

## 概要

指示者LLM（Orchestrator LLM）と作業者LLM（Worker LLM）を連携させ、複雑なタスクを協調して実行するオーケストレーションの仕組みを設計します。これにより、より高度な問題解決能力と柔軟性を提供します。

## 役割定義

- **指示者LLM (Orchestrator LLM)**:
  - ユーザーからの要求を理解し、タスクを分解します。
  - 分解されたタスクを作業者LLMに割り当てます。
  - 作業者LLMからの結果を統合し、最終的な応答を生成します。
  - 必要に応じて、作業者LLMに再指示を出します。
- **作業者LLM (Worker LLM)**:
  - 指示者LLMから割り当てられた特定のサブタスクを実行します。
  - 実行結果を指示者LLMに報告します。
  - 必要に応じて、外部ツール（未実装）を使用します。

## 連携プロトコル

指示者LLMと作業者LLM間のコミュニケーションには、MCPを拡張したプロトコルを使用することを検討します。具体的には、以下のメッセージタイプを定義します。

### 指示者LLM -> 作業者LLM

- `assign_task`: 作業者LLMにサブタスクを割り当てます。
  ```json
  {
    "type": "assign_task",
    "payload": {
      "task_id": "一意のタスクID",
      "description": "サブタスクの説明",
      "input": {
        /* サブタスクに必要な入力データ */
      }
    }
  }
  ```

### 作業者LLM -> 指示者LLM

- `task_result`: サブタスクの実行結果を報告します。
  ```json
  {
    "type": "task_result",
    "payload": {
      "task_id": "関連するタスクID",
      "status": "completed" | "failed" | "needs_clarification",
      "output": { /* 実行結果データ */ },
      "message": "ステータスに関するメッセージ (例: エラーメッセージ、質問)"
    }
  }
  ```

## ワークフロー管理

MCPサーバーがオーケストレーションのハブとなり、指示者LLMと作業者LLM間のメッセージングを仲介します。サーバーは、タスクの状態を追跡し、必要に応じてLLMにメッセージをルーティングします。

## 実装の検討事項

- **LLMの選択**: 指示者LLMと作業者LLMには、異なる特性を持つモデル（例: 指示者には推論能力の高いモデル、作業者には特定のタスクに特化したモデル）を割り当てられるようにします。
- **コンテキストの共有**: 指示者LLMと作業者LLM間で、関連するコンテキスト（会話履歴、中間結果など）を効率的に共有する仕組みを検討します。
- **エラーハンドリングとリカバリ**: 作業者LLMが失敗した場合の指示者LLMによるリカバリ戦略を設計します。
- **ループ検出と終了条件**: 無限ループを防ぐためのメカニズムと、タスクの終了条件を定義します。

## 今後のステップ

- 指示者LLMと作業者LLMのプロトタイプ実装。
- ワークフロー管理ロジックの実装。
- ツール利用との連携。
